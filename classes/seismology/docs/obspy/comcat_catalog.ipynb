{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from libcomcat.dataframes import get_phase_dataframe, get_magnitude_data_frame, get_detail_data_frame, get_history_data_frame\n",
    "from libcomcat.search import get_event_by_id\n",
    "from libcomcat.search import search\n",
    "from libcomcat.classes import DetailEvent, SummaryEvent\n",
    "from libcomcat.utils import HEADERS, TIMEOUT\n",
    "\n",
    "from obspy.io.quakeml.core import Unpickler\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_path = Path(\"phase\")\n",
    "if not phase_path.exists():\n",
    "    phase_path.mkdir()\n",
    "event_path = Path(\"event\")\n",
    "if not event_path.exists():\n",
    "    event_path.mkdir()\n",
    "raw_event_path = Path(\"raw_event\")\n",
    "if not raw_event_path.exists():\n",
    "    raw_event_path.mkdir()\n",
    "raw_phase_path = Path(\"raw_phase\")\n",
    "if not raw_phase_path.exists():\n",
    "    raw_phase_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = 'nc73201181'\n",
    "detail = get_event_by_id(event_id, includesuperseded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_event_path / f\"{event_id}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(detail, f)\n",
    "\n",
    "# print(detail)\n",
    "# with open(raw_event_path / f\"{event_id}.pkl\", \"rb\") as f:\n",
    "#     x = pickle.load(f)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pick(pick, type='pick'):\n",
    "    tmp_pick = {}\n",
    "    if type == 'pick':\n",
    "        tmp_pick[\"resource_id\"] = pick.resource_id\n",
    "        tmp_pick[\"network\"] = pick.waveform_id.network_code\n",
    "        tmp_pick[\"station\"] = pick.waveform_id.station_code\n",
    "        tmp_pick[\"channel\"] = pick.waveform_id.channel_code\n",
    "        tmp_pick[\"location\"] = pick.waveform_id.location_code\n",
    "        tmp_pick[\"phase_time\"] = pick.time.datetime.isoformat(timespec='milliseconds')\n",
    "        tmp_pick[\"oneset\"] = pick.onset\n",
    "        tmp_pick[\"polarity\"] = pick.polarity\n",
    "        tmp_pick[\"evaluation_mode\"] = pick.evaluation_mode\n",
    "        tmp_pick[\"evaluation_status\"] = pick.evaluation_status\n",
    "    elif type == 'arrival':\n",
    "        tmp_pick[\"resource_id\"] = pick.pick_id\n",
    "        tmp_pick[\"phase_type\"] = pick.phase\n",
    "        tmp_pick[\"azimuth\"] = pick.azimuth\n",
    "        tmp_pick[\"distance\"] = pick.distance\n",
    "        tmp_pick[\"takeoff_angle\"] = pick.takeoff_angle\n",
    "        tmp_pick[\"time_residual\"] = pick.time_residual\n",
    "        tmp_pick[\"time_weight\"] = pick.time_weight\n",
    "        tmp_pick[\"time_correction\"] = pick.time_correction\n",
    "    else:\n",
    "        raise ValueError(\"type must be 'pick' or 'arrival'\")\n",
    "\n",
    "    return tmp_pick\n",
    "\n",
    "def add_pick(pick_dict, pick):\n",
    "\n",
    "    if pick[\"resource_id\"] not in pick_dict:\n",
    "        pick_dict[pick[\"resource_id\"]] = pick\n",
    "    else:\n",
    "        pick_dict[pick[\"resource_id\"]].update(pick)\n",
    "    \n",
    "    return pick_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_df = []\n",
    "\n",
    "origins_phase = detail.getProducts('phase-data', source=\"all\")\n",
    "# for origin in origins_phase:\n",
    "#     for k in origin.properties:\n",
    "#         print(k, origin[k])\n",
    "\n",
    "for origin in origins_phase:\n",
    "    # for k in origin.properties:\n",
    "    #     print(k, origin[k])\n",
    "    \n",
    "    quakeurl = origin.getContentURL('quakeml.xml')\n",
    "\n",
    "    with open(raw_phase_path / f\"{event_id}_{origin.source}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(origin, f)\n",
    "\n",
    "    # print(origin)\n",
    "    # with open(raw_phase_path / f\"{event_id}_{origin.source}.pkl\", \"rb\") as f:\n",
    "    #     x = pickle.load(f)\n",
    "    # print(x)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(quakeurl, timeout=TIMEOUT, headers=HEADERS)\n",
    "        data = response.text.encode('utf-8')\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    unpickler = Unpickler()\n",
    "    try:\n",
    "        catalog = unpickler.loads(data)\n",
    "    except Exception as e:\n",
    "        fmt = 'Could not parse QuakeML from %s due to error: %s'\n",
    "        continue\n",
    "    \n",
    "    pick_dict = {}\n",
    "    for catevent in catalog.events:\n",
    "        for pick in catevent.picks:\n",
    "            pick = parse_pick(pick, type=\"pick\")\n",
    "            add_pick(pick_dict, pick)\n",
    "        for tmp_origin in catevent.origins:\n",
    "            for pick in tmp_origin.arrivals:\n",
    "                pick = parse_pick(pick, type=\"arrival\")\n",
    "                add_pick(pick_dict, pick)\n",
    "    pick_df.append(pd.DataFrame.from_dict(pick_dict, orient='index'))\n",
    "\n",
    "pick_df = pd.concat(pick_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_df.to_csv(phase_path/f'{event_id}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dict = {}\n",
    "\n",
    "for k in detail.properties:\n",
    "    if k != \"products\":\n",
    "        # print(k, detail[k])\n",
    "        event_dict[k] = detail[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_fc = detail.getProducts('focal-mechanism')\n",
    "for origin in origins_fc:\n",
    "    for k in origin.properties:\n",
    "        # print(k, origin[k])\n",
    "        event_dict[k] = origin[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_mt = detail.getProducts('moment-tensor')\n",
    "for origin in origins_mt:\n",
    "    for k in origin.properties:\n",
    "        # print(k, origin[k])\n",
    "        event_dict[k] = origin[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = pd.DataFrame.from_dict(event_dict, orient='index').T\n",
    "event_df.to_csv(event_path/f'{event_id}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_phase_dataframe(detail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_magnitude_data_frame(detail, catalog=\"us\", magtype=\"ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_history_data_frame(detail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_events = search(starttime=datetime(1994, 1, 17, 12, 30), endtime=datetime(1994, 1, 18, 12, 35),\n",
    "#                    maxradiuskm=2, latitude=34.213, longitude=-118.537)\n",
    "# detail_df = get_detail_data_frame(summary_events)\n",
    "# print(detail_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comcat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b43c5312267192322fd95d3ee68862685d033482b4955328bf4db877288652a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
